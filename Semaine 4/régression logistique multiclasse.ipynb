{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multiclass_Logistic_Regression_Red_Wine_FrenchTranslation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dphi-official/Bootcamp-de-sur-la-Science-des-donn-es/blob/master/Semaine%204/r%C3%A9gression%20logistique%20multiclasse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGb7BPXkCnmP"
      },
      "source": [
        "\n",
        "# Présentation de la régression logistique multi-classes\n",
        "Nous avons déjà découvert la régression logistique au cours de la [semaine # 3_Day # 6](https://www.google.com/url?q=https://docs.google.com/presentation/d/10mkWll_9s8LkZpy-SzRWQjFr2ay6VppgpjkBVs2HSvM/edit?usp%3Dsharing&sa=D&ust=1592317719588000&usg=AFQjCNFKHARql8iSSd6XH09heRI58Gkk7Q) et construisez un modèle de régression logistique sur les données d'assurance dans [ce cahier](https://github.com/dphi-official/Data_Science_Bootcamp/blob/master/Week3/Logistic_Regression/Logistic_Regression_Insurance.ipynb). Dans le cahier précédent, nous avions construit une régression logistique binaire car la variable cible (c.-à-d. Assurance_achetée) dans les données d'assurance a deux classes 1 (assurance achetée) et 0 (n'a pas acheté d'assurance). Dans ce cahier, nous parlerons de la régression logistique multi-classes.\n",
        "\n",
        "**Régression logistique multi-classes:** Ici, la variable cible a plus de deux classes / catégories possibles. Par exemple, le salaire d'un employé peut être classé dans la catégorie **«faible», «moyen» et «élevé»**. Il existe deux types de régression logistique multi-classes:\n",
        "\n",
        "1. **Régression logistique multinomiale:**\n",
        "La variable cible a trois classes / catégories ou plus qui ne sont pas dans un ordre particulier. Donc, il y a trois catégories nominales ou plus.\n",
        "Exemples: Fruits (pomme, mangue, orange et banane), profession (par exemple, avec cinq groupes: chirurgien, médecin, infirmière, dentiste, thérapeute)\n",
        "\n",
        "2. **Régression logistique ordinale:**\n",
        "La variable cible comprend au moins trois catégories ordinales. Donc, il y a un ordre intrinsèque impliqué dans les catégories.\n",
        "Par exemple, les performances des élèves peuvent être classées comme médiocres, moyennes, bonnes et excellentes, le salaire d'un employé peut être classé comme **'faible', 'moyen' et 'élevé'**\n",
        "\n",
        "## Agenda\n",
        "* À propos de l'ensemble de données\n",
        "* Chargement des bibliothèques et des données\n",
        "* Comprendre les données\n",
        "* Séparation des variables d'entrée et de sortie\n",
        "* Fractionnement des données en train et ensembles de test\n",
        "* Construire le modèle\n",
        "*  Prédiction\n",
        "* Vérifiez le modèle Performace\n",
        "\n",
        "\n",
        "## À propos de l'ensemble de données\n",
        "J'espère que vous vous êtes tous souvenus de l'ensemble de données sur le vin sur lequel nous avons effectué une analyse exploratoire des données. Ici, nous ne prendrons que les données sur le vin rouge. Compte tenu de différents tests physico-chimiques, nous voulons prédire la qualité du vin dans une plage de 1 à 10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQYAUiwVNfe6"
      },
      "source": [
        "## Chargement des bibliothèques\n",
        "Toutes les fonctionnalités Python ne sont pas chargées dans notre environnement de travail par défaut (même si elles sont déjà installées dans votre système). Ainsi, nous importons chaque bibliothèque que nous voulons utiliser.\n",
        "\n",
        "En science des données, numpy et pandas sont les bibliothèques les plus couramment utilisées. Numpy est nécessaire pour les calculs tels que les moyennes, les médianes, les racines carrées, etc. Pandas est utilisé pour le traitement des données et les trames de données. Nous avons choisi des noms d'alias pour nos bibliothèques par souci de commodité (numpy -> np et pandas -> pd)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnyoDUYlCfgq"
      },
      "source": [
        "import numpy as np        # Fundamental package for linear algebra and multidimensional arrays\n",
        "import pandas as pd       # Data analysis and manipultion tool\n",
        "\n",
        "# To ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDu_ZilmOf1H"
      },
      "source": [
        "## Chargement des données\n",
        "Le module Pandas est utilisé pour lire les fichiers. Nous avons nos données au format «.csv». Nous utiliserons la fonction 'read_csv ()' pour charger les données."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl5O8JvJOVXG"
      },
      "source": [
        "# In read_csv() function, we have passed the location to where the files are located in the UCI website. The data is separated by ';'\n",
        "# so we used separator as ';' (sep = \";\")\n",
        "red_wine_data = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\", sep=\";\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6wTwfWgO5Le"
      },
      "source": [
        "## Comprendre les données\n",
        "Voyons à quoi ressemblent nos données."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYc_H0DTOr5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "a9a3eee1-a94c-4614-b219-f4c8503c3832"
      },
      "source": [
        "# Red Wine\n",
        "red_wine_data.head() "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
              "0            7.4              0.70         0.00  ...       0.56      9.4        5\n",
              "1            7.8              0.88         0.00  ...       0.68      9.8        5\n",
              "2            7.8              0.76         0.04  ...       0.65      9.8        5\n",
              "3           11.2              0.28         0.56  ...       0.58      9.8        6\n",
              "4            7.4              0.70         0.00  ...       0.56      9.4        5\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GZNwmuZVVuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b488efed-1767-40eb-e9ad-db4016b80e71"
      },
      "source": [
        "red_wine_data.columns"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
              "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
              "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUzJB6ALUZvR"
      },
      "source": [
        "### Verschiedene Attribute\n",
        "**Variables d'entrée (basées sur des tests physico-chimiques):**\n",
        "1. fixed acidity\n",
        "2. volatile acidity\n",
        "3. citric acid\n",
        "4. residual sugar\n",
        "5. chlorides\n",
        "6. free sulfur dioxide\n",
        "7. total sulfur dioxide\n",
        "8. density\n",
        "9.  pH\n",
        "10.  sulphates\n",
        "11.  alcohol\n",
        "**Variable de sortie (basée sur les données sensorielles):**\n",
        "12. quality (score between 0 and 10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jgMymMeRCBe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "434a69ff-063f-4b0f-872d-e25613bdbf25"
      },
      "source": [
        "# Basic statistical details about data\n",
        "red_wine_data.describe()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8.319637</td>\n",
              "      <td>0.527821</td>\n",
              "      <td>0.270976</td>\n",
              "      <td>2.538806</td>\n",
              "      <td>0.087467</td>\n",
              "      <td>15.874922</td>\n",
              "      <td>46.467792</td>\n",
              "      <td>0.996747</td>\n",
              "      <td>3.311113</td>\n",
              "      <td>0.658149</td>\n",
              "      <td>10.422983</td>\n",
              "      <td>5.636023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.741096</td>\n",
              "      <td>0.179060</td>\n",
              "      <td>0.194801</td>\n",
              "      <td>1.409928</td>\n",
              "      <td>0.047065</td>\n",
              "      <td>10.460157</td>\n",
              "      <td>32.895324</td>\n",
              "      <td>0.001887</td>\n",
              "      <td>0.154386</td>\n",
              "      <td>0.169507</td>\n",
              "      <td>1.065668</td>\n",
              "      <td>0.807569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.600000</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.012000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.990070</td>\n",
              "      <td>2.740000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>7.100000</td>\n",
              "      <td>0.390000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>1.900000</td>\n",
              "      <td>0.070000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.995600</td>\n",
              "      <td>3.210000</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.900000</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>0.079000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>0.996750</td>\n",
              "      <td>3.310000</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>10.200000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9.200000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>2.600000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.997835</td>\n",
              "      <td>3.400000</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>11.100000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>15.900000</td>\n",
              "      <td>1.580000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>0.611000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>289.000000</td>\n",
              "      <td>1.003690</td>\n",
              "      <td>4.010000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>14.900000</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       fixed acidity  volatile acidity  ...      alcohol      quality\n",
              "count    1599.000000       1599.000000  ...  1599.000000  1599.000000\n",
              "mean        8.319637          0.527821  ...    10.422983     5.636023\n",
              "std         1.741096          0.179060  ...     1.065668     0.807569\n",
              "min         4.600000          0.120000  ...     8.400000     3.000000\n",
              "25%         7.100000          0.390000  ...     9.500000     5.000000\n",
              "50%         7.900000          0.520000  ...    10.200000     6.000000\n",
              "75%         9.200000          0.640000  ...    11.100000     6.000000\n",
              "max        15.900000          1.580000  ...    14.900000     8.000000\n",
              "\n",
              "[8 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX7y5M8pWW9m"
      },
      "source": [
        "Voyons la variable cible «qualité»."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdbepaGiWbDu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "c770cd9e-71a8-4753-8ad6-d5e34bdcacfb"
      },
      "source": [
        "red_wine_data.quality.value_counts().plot(kind = 'bar')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe88d401358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzyzsV5RWjR8"
      },
      "source": [
        "On peut observer ici plus de vins de qualité moyenne que de mauvaise qualité et de bonne qualité. C'est ce que nous avions observé dans notre cahier EDA de données sur le vin."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7UacnWPVsYP"
      },
      "source": [
        "Nous avons déjà fait la partie EDA de cet ensemble de données dans notre cahier précédent. Nous n'allons donc pas nous plonger davantage dans l'EDA ici. Séparons les variables indépendantes et dépendantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqZidFhVV8EV"
      },
      "source": [
        "### Séparation des fonctionnalités d'entrée et des fonctionnalités de sortie\n",
        "Avant de créer un modèle d'apprentissage automatique, nous séparons toujours les variables d'entrée et les variables de sortie. Les variables d'entrée sont les quantités dont les valeurs sont modifiées naturellement dans une expérience, tandis que la variable de sortie est celle dont les valeurs dépendent des variables d'entrée. Ainsi, les variables d'entrée sont également appelées variables indépendantes car leurs valeurs ne dépendent d'aucune autre quantité, et les variables de sortie sont également appelées variables dépendantes car ses valeurs dépendent d'autres variables, c'est-à-dire les variables d'entrée. Comme ici dans ces données, nous pouvons voir que le fait qu'une personne achète une assurance ou non dépend de l'âge de cette personne\n",
        "\n",
        "Par convention, les variables d'entrée sont représentées par «X» et les variables de sortie par «y»."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8vuUC95Rpm3"
      },
      "source": [
        "# Input/independent variables\n",
        "X = red_wine_data.drop('quality', axis = 1)   # her we are droping the quality feature as this is the target and 'X' is input features, the changes are not \n",
        "                                              # made inplace as we have not used 'inplace = True'\n",
        "\n",
        "y = red_wine_data.quality             # Output/Dependent variable"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz-95nrxXKFX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df817658-d0b7-40cb-cff1-b64a416c593b"
      },
      "source": [
        "# Let's check the shapes of X and y\n",
        "print(\"Shape: \", X.shape, \"Dimension: \", X.ndim)\n",
        "print(\"Shape: \", y.shape, \"Dimension: \", y.ndim)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape:  (1599, 11) Dimension:  2\n",
            "Shape:  (1599,) Dimension:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV17WuFaXjf1"
      },
      "source": [
        "Nous avions discuté dans le cahier précédent que la variable d'entrée doit être un tableau 2D et la cible d'un tableau 1D."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke41Lb-zYAcb"
      },
      "source": [
        "### Diviser les données en train et ensemble de test\n",
        "Nous voulons vérifier les performances du modèle que nous avons construit. À cette fin, nous divisons toujours (à la fois les données d'entrée et de sortie) les données données en ensemble d'apprentissage qui sera utilisé pour entraîner le modèle, et ensemble de test qui sera utilisé pour vérifier avec quelle précision le modèle prévoit les résultats.\n",
        "\n",
        "Pour cela, nous avons une classe appelée 'train_test_split' dans le module 'sklearn.model_selection'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f55Wc1s1XidB"
      },
      "source": [
        "# import train_test_split\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3S-WWcwYI86"
      },
      "source": [
        "# split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state = 42)\n",
        "\n",
        "# X_train: independent/input feature data for training the model\n",
        "# y_train: dependent/output feature data for training the model\n",
        "# X_test: independent/input feature data for testing the model; will be used to predict the output values\n",
        "# y_test: original dependent/output values of X_test; We will compare this values with our predicted values to check the performance of our built model.\n",
        " \n",
        "# test_size = 0.30: 30% of the data will go for test set and 70% of the data will go for train set\n",
        "# random_state = 42: this will fix the split i.e. there will be same split for each time you run the code"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MCJEiWPYPrU"
      },
      "source": [
        "## Modèle de bâtiment\n",
        "Maintenant, nous sommes enfin prêts et nous pouvons former le modèle.\n",
        "\n",
        "Tout d'abord, nous devons importer notre modèle - Régression logistique (encore une fois, en utilisant la bibliothèque sklearn).\n",
        "\n",
        "Ensuite, nous alimenterions le modèle à la fois avec les données (X_train) et les réponses pour ces données (y_train)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW-t4hTeYMnE"
      },
      "source": [
        "# import Logistic Regression from sklearn.linear_model\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJAwU6RdYT3c"
      },
      "source": [
        "log_model = LogisticRegression()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b7PRDhmY8J1"
      },
      "source": [
        "### !!!Attention\n",
        "Les différentes colonnes de cet ensemble de données sont à des échelles différentes. On peut obtenir «ConvergenceWarning» ici lors de l'ajustement du modèle. Veuillez ignorer ceci pour ici. Si vous souhaitez vous débarrasser de cette erreur, mettez à l'échelle vos données."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xmQtKTbYYbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43ab5d0a-8162-4dc5-d982-14c27f3ecf02"
      },
      "source": [
        "# Fit the model\n",
        "log_model.fit(X_train, y_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W49ndZ6-ZniC"
      },
      "source": [
        "L'entraînement se déroule dans la troisième ligne (la fonction «fit»)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-ShX9-uaAWy"
      },
      "source": [
        "**Point à noter:**\n",
        "LogisticRegression (C = 1.0, class_weight = None, dual = False, fit_intercept = True,\n",
        "                    intercept_scaling = 1, l1_ratio = Aucun, max_iter = 100,\n",
        "                    multi_class = 'auto', n_jobs = Aucun, pénalité = 'l2',\n",
        "                    random_state = Aucun, solveur = 'lbfgs', tol = 0,0001, verbeux = 0,\n",
        "                    warm_start = Faux)\n",
        "\n",
        "Si vous observez clairement la sortie ci-dessus que vous avez obtenue après avoir ajusté le modèle, il existe un argument appelé «multi_class» qui est «auto» par défaut. Si vous revenez en arrière et voyez les données d'assurance, l'argument «multi_class» était toujours «auto». Ici, «auto» effectue une sélection automatique de binaire et multinomial. Si les données sont une classification binaire 'auto' effectue une classification binaire, et si les données sont une classification multiple, 'auto' effectue une classification multiple.\n",
        "\n",
        "Remarque: vous pouvez également changer «auto» en «ovr». Ici, «ovr» ne fait que des classifications binaires.\n",
        "\n",
        "Plus de détails: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocweqF_McEWN"
      },
      "source": [
        "### Prédiction\n",
        "Maintenant, le modèle de régression logistique (c'est-à-dire log_model) est formé à l'aide des données X_train et y_trian. Prédisons la valeur cible (c'est-à-dire la qualité du vin) pour les données X_test. Nous utilisons la méthode \"predire ()\" pour la prédiction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVi4HHKaYbcN"
      },
      "source": [
        "predictions = log_model.predict(X_test)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DorCZd7DcMqK"
      },
      "source": [
        "Nous avons déjà des valeurs cibles réelles (c'est-à-dire y_test) pour X_test. Comparons y_test et la valeur prédite pour X_test par notre log_model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFZIhFU8cIe-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c229e32-cd99-4818-aa23-4c820b116929"
      },
      "source": [
        "y_test.values"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 5, 6, 5, 6, 5, 5, 5, 5, 6, 7, 3, 5, 5, 6, 7, 5, 7, 8, 5, 5, 6,\n",
              "       5, 6, 6, 6, 7, 6, 5, 6, 5, 5, 6, 5, 6, 5, 7, 5, 4, 6, 5, 5, 7, 5,\n",
              "       5, 6, 7, 6, 5, 6, 5, 5, 5, 7, 6, 6, 6, 5, 5, 5, 5, 7, 5, 6, 6, 5,\n",
              "       6, 5, 6, 5, 6, 4, 6, 6, 6, 5, 8, 5, 6, 6, 5, 6, 5, 6, 6, 7, 5, 6,\n",
              "       7, 4, 7, 6, 5, 5, 5, 6, 5, 6, 5, 6, 5, 5, 5, 7, 6, 7, 6, 5, 6, 5,\n",
              "       8, 5, 6, 5, 6, 7, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 7, 6, 5, 5, 6, 5,\n",
              "       5, 5, 6, 5, 5, 5, 5, 6, 7, 6, 8, 5, 5, 5, 6, 6, 6, 5, 6, 7, 6, 5,\n",
              "       6, 5, 5, 6, 6, 6, 7, 5, 7, 5, 5, 5, 6, 6, 5, 5, 6, 5, 7, 6, 7, 6,\n",
              "       6, 5, 5, 6, 4, 6, 5, 7, 5, 5, 4, 5, 7, 6, 5, 6, 6, 7, 6, 5, 5, 6,\n",
              "       5, 7, 5, 6, 6, 5, 7, 5, 5, 5, 6, 7, 7, 5, 5, 6, 6, 7, 6, 5, 6, 6,\n",
              "       6, 6, 6, 7, 4, 5, 5, 7, 5, 5, 5, 5, 6, 6, 5, 7, 5, 6, 6, 6, 5, 4,\n",
              "       6, 7, 6, 7, 5, 6, 6, 5, 5, 6, 5, 6, 4, 5, 6, 6, 5, 6, 6, 5, 5, 6,\n",
              "       7, 7, 6, 5, 6, 6, 5, 6, 5, 6, 5, 5, 5, 6, 6, 6, 7, 5, 5, 6, 5, 7,\n",
              "       5, 6, 4, 6, 6, 8, 6, 5, 5, 6, 5, 7, 6, 6, 5, 5, 7, 6, 6, 5, 6, 6,\n",
              "       5, 7, 6, 6, 6, 6, 5, 6, 5, 5, 6, 4, 6, 6, 6, 5, 5, 5, 6, 6, 6, 6,\n",
              "       4, 7, 6, 6, 6, 5, 6, 7, 5, 5, 6, 7, 5, 5, 6, 5, 6, 5, 6, 5, 5, 6,\n",
              "       5, 6, 6, 6, 5, 6, 4, 5, 4, 5, 5, 6, 5, 6, 6, 5, 5, 5, 5, 5, 6, 5,\n",
              "       6, 6, 6, 5, 5, 6, 5, 5, 6, 6, 6, 7, 6, 5, 5, 6, 6, 5, 5, 6, 7, 6,\n",
              "       5, 6, 5, 7, 5, 5, 7, 5, 6, 7, 7, 6, 6, 5, 6, 6, 7, 6, 5, 7, 6, 6,\n",
              "       6, 5, 5, 5, 5, 5, 6, 5, 5, 5, 7, 6, 7, 6, 4, 5, 7, 5, 5, 5, 6, 6,\n",
              "       6, 6, 6, 5, 6, 5, 6, 5, 6, 6, 7, 4, 6, 5, 6, 6, 7, 5, 7, 5, 5, 6,\n",
              "       5, 5, 6, 5, 6, 5, 5, 6, 6, 4, 5, 6, 5, 7, 8, 6, 7, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlAZxEyTcPcX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4b57547-d936-49ea-e4cf-7385acc9242c"
      },
      "source": [
        "predictions"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 5, 5, 5, 6, 5, 5, 5, 6, 6, 6, 5, 5, 5, 5, 6, 5, 5, 6, 5, 6, 5,\n",
              "       6, 6, 5, 5, 6, 5, 5, 6, 5, 6, 6, 5, 5, 5, 6, 6, 6, 6, 5, 5, 6, 5,\n",
              "       6, 6, 6, 5, 5, 6, 5, 5, 6, 6, 5, 5, 6, 5, 6, 5, 5, 6, 5, 5, 6, 5,\n",
              "       6, 5, 6, 5, 6, 5, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6, 5, 6, 6, 6, 5, 6,\n",
              "       6, 5, 6, 5, 6, 6, 5, 6, 5, 6, 5, 5, 5, 5, 6, 6, 6, 6, 5, 5, 6, 5,\n",
              "       6, 5, 6, 5, 6, 6, 6, 5, 5, 6, 6, 5, 5, 5, 5, 5, 6, 6, 5, 6, 6, 5,\n",
              "       5, 6, 6, 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 5, 6,\n",
              "       6, 6, 5, 6, 5, 6, 6, 6, 6, 5, 5, 6, 5, 5, 5, 5, 5, 5, 6, 5, 5, 6,\n",
              "       6, 5, 5, 5, 5, 6, 5, 7, 5, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 5, 5, 5,\n",
              "       5, 6, 5, 5, 5, 5, 6, 6, 5, 5, 5, 6, 6, 5, 6, 6, 6, 6, 5, 5, 6, 5,\n",
              "       5, 6, 6, 6, 5, 5, 5, 6, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 5, 5, 6, 5,\n",
              "       6, 6, 6, 5, 6, 5, 7, 5, 6, 6, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 5, 7,\n",
              "       6, 6, 5, 5, 6, 6, 5, 6, 5, 5, 5, 6, 6, 6, 6, 5, 6, 5, 5, 5, 5, 6,\n",
              "       5, 6, 5, 6, 5, 7, 5, 5, 5, 6, 5, 6, 6, 6, 6, 5, 6, 5, 5, 5, 6, 6,\n",
              "       6, 6, 6, 6, 5, 5, 5, 6, 5, 5, 6, 5, 6, 6, 5, 5, 5, 5, 6, 6, 5, 6,\n",
              "       6, 6, 5, 5, 5, 6, 6, 6, 5, 5, 6, 6, 6, 5, 6, 5, 6, 5, 6, 6, 5, 6,\n",
              "       5, 5, 5, 5, 5, 5, 5, 6, 6, 5, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 6, 6,\n",
              "       5, 6, 5, 6, 5, 5, 5, 6, 6, 5, 6, 6, 6, 5, 5, 6, 6, 6, 5, 5, 6, 6,\n",
              "       6, 5, 5, 6, 5, 5, 6, 5, 5, 6, 6, 6, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6,\n",
              "       6, 6, 6, 5, 5, 5, 5, 6, 5, 5, 6, 5, 6, 5, 5, 5, 6, 5, 5, 6, 5, 6,\n",
              "       6, 6, 6, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 5, 5, 6, 6, 5, 6, 5, 5, 5,\n",
              "       6, 5, 6, 5, 5, 5, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N03lPHnjcYFC"
      },
      "source": [
        "### Performance du modèle\n",
        "Nous pouvons également vérifier la précision de notre modèle en utilisant la classe 'precision_score' de 'sklearn.metrics'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgHXp0zY3wB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63385e8d-4935-4e0d-c3d5-03d8326ab845"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, predictions)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   1,   0,   0,   0],\n",
              "       [  0,   0,  11,   6,   0,   0],\n",
              "       [  0,   0, 139,  56,   0,   0],\n",
              "       [  0,   0,  77, 121,   2,   0],\n",
              "       [  0,   0,   4,  56,   1,   0],\n",
              "       [  0,   0,   0,   5,   1,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WllwJsct4Oln"
      },
      "source": [
        "Encore une fois, si vous observez ici, les faux positifs de classe (au-dessus de la diagonale principale) et les faux négatifs de classe (en dessous de la diagonale principale) sont presque symétriques. Le score de précision est donc une métrique importante ici."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJFT1qOicTWj"
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "992-t06DccS6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "600e9932-680b-426d-8d6c-6fc789609b7c"
      },
      "source": [
        "accuracy_score(y_test, predictions)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.54375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DETRhfShcgyb"
      },
      "source": [
        "Notre modèle prévoit des résultats corrects à 54,37%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn1yJeMXctqy"
      },
      "source": [
        "**Merci d'avoir lu le cahier !!!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9X6ggkAc1ET"
      },
      "source": [
        "## Exercice\n",
        "Utilisez le lien de données brutes des données d'iris: https://raw.githubusercontent.com/dphi-official/Datasets/master/iris.csv\n",
        "\n",
        "**Des exercices**\n",
        "* Modèle de régression logistique du train pour cet ensemble de données\n",
        "* Prédire la sortie pour les données de test\n",
        "* Découvrez la précision du modèle que vous avez construit."
      ]
    }
  ]
}